{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: DeprecationWarning: decodestring() is a deprecated alias since Python 3.1, use decodebytes()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded train-images-idx3-ubyte.gz\n",
      "Already downloaded train-labels-idx1-ubyte.gz\n",
      "Already downloaded t10k-images-idx3-ubyte.gz\n",
      "Already downloaded t10k-labels-idx1-ubyte.gz\n",
      "magic number 2051\n",
      "image count 10000\n",
      "rows 28\n",
      "columns 28\n",
      "First 10 pixels: [0 0 0 0 0 0 0 0 0 0]\n",
      "magic number 2049\n",
      "label count 10000\n",
      "First label: 7\n",
      "Extracting /tmp/mnist-data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/mnist-data/t10k-images-idx3-ubyte.gz\n",
      "Training data shape (60000, 28, 28, 1)\n",
      "Extracting /tmp/mnist-data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/mnist-data/t10k-labels-idx1-ubyte.gz\n",
      "Training labels shape (60000, 10)\n",
      "First label vector [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Second label vector [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Validation shape (5000, 28, 28, 1)\n",
      "Train size 55000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n",
      "WARNING:tensorflow:From <ipython-input-1-124d31656f35>:408: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Done\n",
      "Done\n",
      "[2.2539364e-04 4.7622274e-05 1.6686800e-03 5.6782908e-05 6.0343212e-01\n",
      " 4.3496944e-02 2.1931737e-05 1.4128677e-04 1.5490383e-05 3.5089377e-01]\n",
      "First prediction 4\n",
      "(60, 10)\n",
      "All predictions [4 4 2 7 7 7 7 7 7 7 7 7 0 8 9 0 7 7 0 7 4 0 5 0 9 9 7 0 7 4 7 7 7 0 7 7 9\n",
      " 7 9 9 0 7 7 7 2 7 0 7 2 9 9 9 9 9 0 7 9 4 8 7]\n",
      "Batch labels [7 3 4 6 1 8 1 0 9 8 0 3 1 2 7 0 2 9 6 0 1 6 7 1 9 7 6 5 5 8 8 3 4 4 8 7 3\n",
      " 6 4 6 6 3 8 8 9 9 4 4 0 7 8 1 0 0 1 8 5 7 1 7]\n",
      "0.06666666666666667\n",
      "Done\n",
      "Step 0 of 916\n",
      "Mini-batch loss: 7.71258 Error: 91.66667 Learning rate: 0.01000\n",
      "Validation error: 88.9%\n",
      "Step 100 of 916\n",
      "Mini-batch loss: 3.30413 Error: 6.66667 Learning rate: 0.01000\n",
      "Validation error: 5.7%\n",
      "Step 200 of 916\n",
      "Mini-batch loss: 3.34098 Error: 10.00000 Learning rate: 0.01000\n",
      "Validation error: 3.8%\n",
      "Step 300 of 916\n",
      "Mini-batch loss: 3.16536 Error: 8.33333 Learning rate: 0.01000\n",
      "Validation error: 3.3%\n",
      "Step 400 of 916\n",
      "Mini-batch loss: 3.12825 Error: 5.00000 Learning rate: 0.01000\n",
      "Validation error: 2.8%\n",
      "Step 500 of 916\n",
      "Mini-batch loss: 2.99378 Error: 0.00000 Learning rate: 0.01000\n",
      "Validation error: 2.5%\n",
      "Step 600 of 916\n",
      "Mini-batch loss: 3.06547 Error: 6.66667 Learning rate: 0.01000\n",
      "Validation error: 2.1%\n",
      "Step 700 of 916\n",
      "Mini-batch loss: 3.14828 Error: 6.66667 Learning rate: 0.01000\n",
      "Validation error: 2.0%\n",
      "Step 800 of 916\n",
      "Mini-batch loss: 3.06323 Error: 5.00000 Learning rate: 0.01000\n",
      "Validation error: 1.9%\n",
      "Step 900 of 916\n",
      "Mini-batch loss: 2.85570 Error: 0.00000 Learning rate: 0.01000\n",
      "Validation error: 2.0%\n",
      "Test error: 2.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assignment 6 - Mimi Trinh\n",
    "# Using sample codes from Canvas for week 6\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from IPython.display import Image\n",
    "import base64\n",
    "Image(data=base64.decodestring(\"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\".encode('utf-8')), embed=True)\n",
    "\n",
    "\n",
    "# We're going to be building a model that recognizes these digits as 5, 0, and 4.\n",
    "# \n",
    "# # Imports and input data\n",
    "# \n",
    "# We'll proceed in steps, beginning with importing and inspecting the MNIST data. This doesn't have anything to do with TensorFlow in particular -- we're just downloading the data archive.\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import os\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "\n",
    "SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\n",
    "WORK_DIRECTORY = \"/tmp/mnist-data\"\n",
    "\n",
    "def maybe_download(filename):\n",
    "    \"\"\"A helper to download the data files if not present.\"\"\"\n",
    "    if not os.path.exists(WORK_DIRECTORY):\n",
    "        os.mkdir(WORK_DIRECTORY)\n",
    "    filepath = os.path.join(WORK_DIRECTORY, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        filepath, _ = urlretrieve(SOURCE_URL + filename, filepath)\n",
    "        statinfo = os.stat(filepath)\n",
    "        print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "    else:\n",
    "        print('Already downloaded', filename)\n",
    "    return filepath\n",
    "\n",
    "train_data_filename = maybe_download('train-images-idx3-ubyte.gz')\n",
    "train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')\n",
    "test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')\n",
    "test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "\n",
    "# ## Working with the images\n",
    "# \n",
    "# Now we have the files, but the format requires a bit of pre-processing before we can work with it. The data is gzipped, requiring us to decompress it. And, each of the images are grayscale-encoded with values from [0, 255]; we'll normalize these to [-0.5, 0.5].\n",
    "# \n",
    "# Let's try to unpack the data using the documented format:\n",
    "# \n",
    "#     [offset] [type]          [value]          [description] \n",
    "#     0000     32 bit integer  0x00000803(2051) magic number \n",
    "#     0004     32 bit integer  60000            number of images \n",
    "#     0008     32 bit integer  28               number of rows \n",
    "#     0012     32 bit integer  28               number of columns \n",
    "#     0016     unsigned byte   ??               pixel \n",
    "#     0017     unsigned byte   ??               pixel \n",
    "#     ........ \n",
    "#     xxxx     unsigned byte   ??               pixel\n",
    "#     \n",
    "# Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).\n",
    "# \n",
    "# We'll start by reading the first image from the test data as a sanity check.\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "import gzip, binascii, struct, numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with gzip.open(test_data_filename) as f:\n",
    "    # Print the header fields.\n",
    "    for field in ['magic number', 'image count', 'rows', 'columns']:\n",
    "        # struct.unpack reads the binary data provided by f.read.\n",
    "        # The format string '>i' decodes a big-endian integer, which\n",
    "        # is the encoding of the data.\n",
    "        print(field, struct.unpack('>i', f.read(4))[0])\n",
    "    \n",
    "    # Read the first 28x28 set of pixel values. \n",
    "    # Each pixel is one byte, [0, 255], a uint8.\n",
    "    buf = f.read(28 * 28)\n",
    "    image = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
    "  \n",
    "    # Print the first few values of image.\n",
    "    print('First 10 pixels:', image[:10])\n",
    "\n",
    "\n",
    "# The first 10 pixels are all 0 values. Not very interesting, but also unsurprising. We'd expect most of the pixel values to be the background color, 0.\n",
    "# \n",
    "# We could print all 28 * 28 values, but what we really need to do to make sure we're reading our data properly is look at an image.\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "\n",
    "# We'll show the image and its pixel value histogram side-by-side.\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "# To interpret the values as a 28x28 image, we need to reshape\n",
    "# the numpy array, which is one dimensional.\n",
    "ax1.imshow(image.reshape(28, 28), cmap=plt.cm.Greys);\n",
    "\n",
    "ax2.hist(image, bins=20, range=[0,255]);\n",
    "\n",
    "\n",
    "# The large number of 0 values correspond to the background of the image, another large mass of value 255 is black, and a mix of grayscale transition values in between.\n",
    "# \n",
    "# Both the image and histogram look sensible. But, it's good practice when training image models to normalize values to be centered around 0.\n",
    "# \n",
    "# We'll do that next. The normalization code is fairly short, and it may be tempting to assume we haven't made mistakes, but we'll double-check by looking at the rendered input and histogram again. Malformed inputs are a surprisingly common source of errors when developing new models.\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "# Let's convert the uint8 image to 32 bit floats and rescale \n",
    "# the values to be centered around 0, between [-0.5, 0.5]. \n",
    "# \n",
    "# We again plot the image and histogram to check that we \n",
    "# haven't mangled the data.\n",
    "scaled = image.astype(numpy.float32)\n",
    "scaled = (scaled - (255 / 2.0)) / 255\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(scaled.reshape(28, 28), cmap=plt.cm.Greys);\n",
    "ax2.hist(scaled, bins=20, range=[-0.5, 0.5]);\n",
    "\n",
    "\n",
    "# Great -- we've retained the correct image data while properly rescaling to the range [-0.5, 0.5].\n",
    "# \n",
    "# ## Reading the labels\n",
    "# \n",
    "# Let's next unpack the test label data. The format here is similar: a magic number followed by a count followed by the labels as `uint8` values. In more detail:\n",
    "# \n",
    "#     [offset] [type]          [value]          [description] \n",
    "#     0000     32 bit integer  0x00000801(2049) magic number (MSB first) \n",
    "#     0004     32 bit integer  10000            number of items \n",
    "#     0008     unsigned byte   ??               label \n",
    "#     0009     unsigned byte   ??               label \n",
    "#     ........ \n",
    "#     xxxx     unsigned byte   ??               label\n",
    "# \n",
    "# As with the image data, let's read  the first test set value to sanity check our input path. We'll expect a 7.\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "with gzip.open(test_labels_filename) as f:\n",
    "    # Print the header fields.\n",
    "    for field in ['magic number', 'label count']:\n",
    "        print(field, struct.unpack('>i', f.read(4))[0])\n",
    "\n",
    "    print('First label:', struct.unpack('B', f.read(1))[0])\n",
    "\n",
    "\n",
    "# Indeed, the first label of the test set is 7.\n",
    "# \n",
    "# ## Forming the training, testing, and validation data sets\n",
    "# \n",
    "# Now that we understand how to read a single element, we can read a much larger set that we'll use for training, testing, and validation.\n",
    "# \n",
    "# ### Image data\n",
    "# \n",
    "# The code below is a generalization of our prototyping above that reads the entire test and training data set.\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "IMAGE_SIZE = 28\n",
    "PIXEL_DEPTH = 255\n",
    "\n",
    "def extract_data(filename, num_images):\n",
    "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "  \n",
    "    For MNIST data, the number of channels is always 1.\n",
    "\n",
    "    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
    "    \"\"\"\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        # Skip the magic number and dimensions; we know these values.\n",
    "        bytestream.read(16)\n",
    "\n",
    "        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images)\n",
    "        data = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.float32)\n",
    "        data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "        data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "        return data\n",
    "\n",
    "train_data = extract_data(train_data_filename, 60000)\n",
    "test_data = extract_data(test_data_filename, 10000)\n",
    "\n",
    "\n",
    "# A crucial difference here is how we `reshape` the array of pixel values. Instead of one image that's 28x28, we now have a set of 60,000 images, each one being 28x28. We also include a number of channels, which for grayscale images as we have here is 1.\n",
    "# \n",
    "# Let's make sure we've got the reshaping parameters right by inspecting the dimensions and the first two images. (Again, mangled input is a very common source of errors.)\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "print('Training data shape', train_data.shape)\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(train_data[0].reshape(28, 28), cmap=plt.cm.Greys);\n",
    "ax2.imshow(train_data[1].reshape(28, 28), cmap=plt.cm.Greys);\n",
    "\n",
    "\n",
    "# Looks good. Now we know how to index our full set of training and test images.\n",
    "\n",
    "# ### Label data\n",
    "# \n",
    "# Let's move on to loading the full set of labels. As is typical in classification problems, we'll convert our input labels into a [1-hot](https://en.wikipedia.org/wiki/One-hot) encoding over a length 10 vector corresponding to 10 digits. The vector [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], for example, would correspond to the digit 1.\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "NUM_LABELS = 10\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"Extract the labels into a 1-hot matrix [image index, label index].\"\"\"\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        # Skip the magic number and count; we know these values.\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
    "    # Convert to dense 1-hot representation.\n",
    "    return (numpy.arange(NUM_LABELS) == labels[:, None]).astype(numpy.float32)\n",
    "\n",
    "train_labels = extract_labels(train_labels_filename, 60000)\n",
    "test_labels = extract_labels(test_labels_filename, 10000)\n",
    "\n",
    "\n",
    "# As with our image data, we'll double-check that our 1-hot encoding of the first few values matches our expectations.\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "print('Training labels shape', train_labels.shape)\n",
    "print('First label vector', train_labels[0])\n",
    "print('Second label vector', train_labels[1])\n",
    "\n",
    "\n",
    "# The 1-hot encoding looks reasonable.\n",
    "# \n",
    "# ### Segmenting data into training, test, and validation\n",
    "# \n",
    "# The final step in preparing our data is to split it into three sets: training, test, and validation. This isn't the format of the original data set, so we'll take a small slice of the training data and treat that as our validation set.\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "VALIDATION_SIZE = 5000\n",
    "\n",
    "validation_data = train_data[:VALIDATION_SIZE, :, :, :]\n",
    "validation_labels = train_labels[:VALIDATION_SIZE]\n",
    "train_data = train_data[VALIDATION_SIZE:, :, :, :]\n",
    "train_labels = train_labels[VALIDATION_SIZE:]\n",
    "\n",
    "train_size = train_labels.shape[0]\n",
    "\n",
    "print('Validation shape', validation_data.shape)\n",
    "print('Train size', train_size)\n",
    "\n",
    "\n",
    "# # Defining the model\n",
    "# \n",
    "# Now that we've prepared our data, we're ready to define our model.\n",
    "# \n",
    "# The comments describe the architecture, which fairly typical of models that process image data. The raw input passes through several [convolution](https://en.wikipedia.org/wiki/Convolutional_neural_network#Convolutional_layer) and [max pooling](https://en.wikipedia.org/wiki/Convolutional_neural_network#Pooling_layer) layers with [rectified linear](https://en.wikipedia.org/wiki/Convolutional_neural_network#ReLU_layer) activations before several fully connected layers and a [softmax](https://en.wikipedia.org/wiki/Convolutional_neural_network#Loss_layer) loss for predicting the output class. During training, we use [dropout](https://en.wikipedia.org/wiki/Convolutional_neural_network#Dropout_method).\n",
    "# \n",
    "# We'll separate our model definition into three steps:\n",
    "# \n",
    "# 1. Defining the variables that will hold the trainable weights.\n",
    "# 1. Defining the basic model graph structure described above. And,\n",
    "# 1. Stamping out several copies of the model graph for training, testing, and validation.\n",
    "# \n",
    "# We'll start with the variables.\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# We'll bundle groups of examples during training for efficiency.\n",
    "# This defines the size of the batch.\n",
    "BATCH_SIZE = 60\n",
    "# We have only one channel in our grayscale images.\n",
    "NUM_CHANNELS = 1\n",
    "# The random seed that defines initialization.\n",
    "SEED = 42\n",
    "\n",
    "# This is where training samples and labels are fed to the graph.\n",
    "# These placeholder nodes will be fed a batch of training data at each\n",
    "# training step, which we'll write once we define the graph structure.\n",
    "train_data_node = tf.placeholder(\n",
    "  tf.float32,\n",
    "  shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "train_labels_node = tf.placeholder(tf.float32,\n",
    "                                   shape=(BATCH_SIZE, NUM_LABELS))\n",
    "\n",
    "# For the validation and test data, we'll just hold the entire dataset in\n",
    "# one constant node.\n",
    "validation_data_node = tf.constant(validation_data)\n",
    "test_data_node = tf.constant(test_data)\n",
    "\n",
    "# The variables below hold all the trainable weights. For each, the\n",
    "# parameter defines how the variables will be initialized.\n",
    "conv1_weights = tf.Variable(\n",
    "  tf.truncated_normal([5, 5, NUM_CHANNELS, 32],  # 5x5 filter, depth 32.\n",
    "                      stddev=0.1,\n",
    "                      seed=SEED))\n",
    "conv1_biases = tf.Variable(tf.zeros([32]))\n",
    "conv2_weights = tf.Variable(\n",
    "  tf.truncated_normal([5, 5, 32, 64],\n",
    "                      stddev=0.1,\n",
    "                      seed=SEED))\n",
    "conv2_biases = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "fc1_weights = tf.Variable(  # fully connected, depth 512.\n",
    "  tf.truncated_normal([IMAGE_SIZE // 4 * IMAGE_SIZE // 4 * 64, 512],\n",
    "                      stddev=0.1,\n",
    "                      seed=SEED))\n",
    "fc1_biases = tf.Variable(tf.constant(0.1, shape=[512]))\n",
    "fc2_weights = tf.Variable(\n",
    "  tf.truncated_normal([512, NUM_LABELS],\n",
    "                      stddev=0.1,\n",
    "                      seed=SEED))\n",
    "fc2_biases = tf.Variable(tf.constant(0.1, shape=[NUM_LABELS]))\n",
    "\n",
    "print('Done')\n",
    "\n",
    "\n",
    "# Now that we've defined the variables to be trained, we're ready to wire them together into a TensorFlow graph.\n",
    "# \n",
    "# We'll define a helper to do this, `model`, which will return copies of the graph suitable for training and testing. Note the `train` argument, which controls whether or not dropout is used in the hidden layer. (We want to use dropout only during training.)\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "def model(data, train=False):\n",
    "    \"\"\"The Model definition.\"\"\"\n",
    "    # 2D convolution, with 'SAME' padding (i.e. the output feature map has\n",
    "    # the same size as the input). Note that {strides} is a 4D array whose\n",
    "    # shape matches the data layout: [image index, y, x, depth].\n",
    "    conv = tf.nn.conv2d(data,\n",
    "                        conv1_weights,\n",
    "                        strides=[1, 1, 1, 1],\n",
    "                        padding='SAME')\n",
    "\n",
    "    # Bias and rectified linear non-linearity.\n",
    "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv1_biases))\n",
    "\n",
    "    # Max pooling. The kernel size spec ksize also follows the layout of\n",
    "    # the data. Here we have a pooling window of 2, and a stride of 2.\n",
    "    pool = tf.nn.max_pool(relu,\n",
    "                          ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1],\n",
    "                          padding='SAME')\n",
    "    conv = tf.nn.conv2d(pool,\n",
    "                        conv2_weights,\n",
    "                        strides=[1, 1, 1, 1],\n",
    "                        padding='SAME')\n",
    "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv2_biases))\n",
    "    pool = tf.nn.max_pool(relu,\n",
    "                          ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "    # Reshape the feature map cuboid into a 2D matrix to feed it to the\n",
    "    # fully connected layers.\n",
    "    pool_shape = pool.get_shape().as_list()\n",
    "    reshape = tf.reshape(\n",
    "        pool,\n",
    "        [pool_shape[0], pool_shape[1] * pool_shape[2] * pool_shape[3]])\n",
    "  \n",
    "    # Fully connected layer. Note that the '+' operation automatically\n",
    "    # broadcasts the biases.\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)\n",
    "\n",
    "    # Add a 50% dropout during training only. Dropout also scales\n",
    "    # activations such that no rescaling is needed at evaluation time.\n",
    "    if train:\n",
    "        hidden = tf.nn.dropout(hidden, 0.5, seed=SEED)\n",
    "    return tf.matmul(hidden, fc2_weights) + fc2_biases\n",
    "\n",
    "print('Done')\n",
    "\n",
    "\n",
    "# Having defined the basic structure of the graph, we're ready to stamp out multiple copies for training, testing, and validation.\n",
    "# \n",
    "# Here, we'll do some customizations depending on which graph we're constructing. `train_prediction` holds the training graph, for which we use cross-entropy loss and weight regularization. We'll adjust the learning rate during training -- that's handled by the `exponential_decay` operation, which is itself an argument to the `MomentumOptimizer` that performs the actual training.\n",
    "# \n",
    "# The vaildation and prediction graphs are much simpler the generate -- we need only create copies of the model with the validation and test inputs and a softmax classifier as the output.\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "# Training computation: logits + cross-entropy loss.\n",
    "logits = model(train_data_node, True)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "  labels=train_labels_node, logits=logits))\n",
    "\n",
    "# L2 regularization for the fully connected parameters.\n",
    "regularizers = (tf.nn.l2_loss(fc1_weights) + tf.nn.l2_loss(fc1_biases) +\n",
    "                tf.nn.l2_loss(fc2_weights) + tf.nn.l2_loss(fc2_biases))\n",
    "# Add the regularization term to the loss.\n",
    "loss += 5e-4 * regularizers\n",
    "\n",
    "# Optimizer: set up a variable that's incremented once per batch and\n",
    "# controls the learning rate decay.\n",
    "batch = tf.Variable(0)\n",
    "# Decay once per epoch, using an exponential schedule starting at 0.01.\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "  0.01,                # Base learning rate.\n",
    "  batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "  train_size,          # Decay step.\n",
    "  0.95,                # Decay rate.\n",
    "  staircase=True)\n",
    "# Use simple momentum for the optimization.\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate,\n",
    "                                       0.9).minimize(loss,\n",
    "                                                     global_step=batch)\n",
    "\n",
    "# Predictions for the minibatch, validation set and test set.\n",
    "train_prediction = tf.nn.softmax(logits)\n",
    "# We'll compute them only once in a while by calling their {eval()} method.\n",
    "validation_prediction = tf.nn.softmax(model(validation_data_node))\n",
    "test_prediction = tf.nn.softmax(model(test_data_node))\n",
    "\n",
    "print('Done')\n",
    "\n",
    "\n",
    "# # Training and visualizing results\n",
    "# \n",
    "# Now that we have the training, test, and validation graphs, we're ready to actually go through the training loop and periodically evaluate loss and error.\n",
    "# \n",
    "# All of these operations take place in the context of a session. In Python, we'd write something like:\n",
    "# \n",
    "#     with tf.Session() as s:\n",
    "#       ...training / test / evaluation loop...\n",
    "#   \n",
    "# But, here, we'll want to keep the session open so we can poke at values as we work out the details of training. The TensorFlow API includes a function for this, `InteractiveSession`.\n",
    "# \n",
    "# We'll start by creating a session and initializing the varibles we defined above.\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "# Create a new interactive session that we'll use in\n",
    "# subsequent code cells.\n",
    "s = tf.InteractiveSession()\n",
    "\n",
    "# Use our newly created session as the default for \n",
    "# subsequent operations.\n",
    "s.as_default()\n",
    "\n",
    "# Initialize all the variables we defined above.\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "\n",
    "# Now we're ready to perform operations on the graph. Let's start with one round of training. We're going to organize our training steps into batches for efficiency; i.e., training using a small set of examples at each step rather than a single example.\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "BATCH_SIZE = 60\n",
    "\n",
    "# Grab the first BATCH_SIZE examples and labels.\n",
    "batch_data = train_data[:BATCH_SIZE, :, :, :]\n",
    "batch_labels = train_labels[:BATCH_SIZE]\n",
    "\n",
    "# This dictionary maps the batch data (as a numpy array) to the\n",
    "# node in the graph it should be fed to.\n",
    "feed_dict = {train_data_node: batch_data,\n",
    "             train_labels_node: batch_labels}\n",
    "\n",
    "# Run the graph and fetch some of the nodes.\n",
    "_, l, lr, predictions = s.run(\n",
    "  [optimizer, loss, learning_rate, train_prediction],\n",
    "  feed_dict=feed_dict)\n",
    "\n",
    "print('Done')\n",
    "\n",
    "\n",
    "# Let's take a look at the predictions. How did we do? Recall that the output will be probabilities over the possible classes, so let's look at those probabilities.\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "print(predictions[0])\n",
    "\n",
    "\n",
    "# As expected without training, the predictions are all noise. Let's write a scoring function that picks the class with the maximum probability and compares with the example's label. We'll start by converting the probability vectors returned by the softmax into predictions we can match against the labels.\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "# The highest probability in the first entry.\n",
    "print('First prediction', numpy.argmax(predictions[0]))\n",
    "\n",
    "# But, predictions is actually a list of BATCH_SIZE probability vectors.\n",
    "print(predictions.shape)\n",
    "\n",
    "# So, we'll take the highest probability for each vector.\n",
    "print('All predictions', numpy.argmax(predictions, 1))\n",
    "\n",
    "\n",
    "# Next, we can do the same thing for our labels -- using `argmax` to convert our 1-hot encoding into a digit class.\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "print('Batch labels', numpy.argmax(batch_labels, 1))\n",
    "\n",
    "\n",
    "# Now we can compare the predicted and label classes to compute the error rate and confusion matrix for this batch.\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "correct = numpy.sum(numpy.argmax(predictions, 1) == numpy.argmax(batch_labels, 1))\n",
    "total = predictions.shape[0]\n",
    "\n",
    "print(float(correct) / float(total))\n",
    "\n",
    "confusions = numpy.zeros([10, 10], numpy.float32)\n",
    "bundled = zip(numpy.argmax(predictions, 1), numpy.argmax(batch_labels, 1))\n",
    "for predicted, actual in bundled:\n",
    "  confusions[predicted, actual] += 1\n",
    "\n",
    "plt.grid(False)\n",
    "plt.xticks(numpy.arange(NUM_LABELS))\n",
    "plt.yticks(numpy.arange(NUM_LABELS))\n",
    "plt.imshow(confusions, cmap=plt.cm.jet, interpolation='nearest');\n",
    "\n",
    "\n",
    "# Now let's wrap this up into our scoring function.\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "def error_rate(predictions, labels):\n",
    "    \"\"\"Return the error rate and confusions.\"\"\"\n",
    "    correct = numpy.sum(numpy.argmax(predictions, 1) == numpy.argmax(labels, 1))\n",
    "    total = predictions.shape[0]\n",
    "\n",
    "    error = 100.0 - (100 * float(correct) / float(total))\n",
    "\n",
    "    confusions = numpy.zeros([10, 10], numpy.float32)\n",
    "    bundled = zip(numpy.argmax(predictions, 1), numpy.argmax(labels, 1))\n",
    "    for predicted, actual in bundled:\n",
    "        confusions[predicted, actual] += 1\n",
    "    \n",
    "    return error, confusions\n",
    "\n",
    "print('Done')\n",
    "\n",
    "\n",
    "# We'll need to train for some time to actually see useful predicted values. Let's define a loop that will go through our data. We'll print the loss and error periodically.\n",
    "# \n",
    "# Here, we want to iterate over the entire data set rather than just the first batch, so we'll need to slice the data to that end.\n",
    "# \n",
    "# (One pass through our training set will take some time on a CPU, so be patient if you are executing this notebook.)\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "# Train over the first 1/4th of our training set.\n",
    "steps = train_size // BATCH_SIZE\n",
    "for step in range(steps):\n",
    "    # Compute the offset of the current minibatch in the data.\n",
    "    # Note that we could use better randomization across epochs.\n",
    "    offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n",
    "    batch_data = train_data[offset:(offset + BATCH_SIZE), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "    # This dictionary maps the batch data (as a numpy array) to the\n",
    "    # node in the graph it should be fed to.\n",
    "    feed_dict = {train_data_node: batch_data,\n",
    "                 train_labels_node: batch_labels}\n",
    "    # Run the graph and fetch some of the nodes.\n",
    "    _, l, lr, predictions = s.run(\n",
    "      [optimizer, loss, learning_rate, train_prediction],\n",
    "      feed_dict=feed_dict)\n",
    "    \n",
    "    # Print out the loss periodically.\n",
    "    if step % 100 == 0:\n",
    "        error, _ = error_rate(predictions, batch_labels)\n",
    "        print('Step %d of %d' % (step, steps))\n",
    "        print('Mini-batch loss: %.5f Error: %.5f Learning rate: %.5f' % (l, error, lr))\n",
    "        print('Validation error: %.1f%%' % error_rate(\n",
    "              validation_prediction.eval(), validation_labels)[0])\n",
    "\n",
    "\n",
    "# The error seems to have gone down. Let's evaluate the results using the test set.\n",
    "# \n",
    "# To help identify rare mispredictions, we'll include the raw count of each (prediction, label) pair in the confusion matrix.\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "test_error, confusions = error_rate(test_prediction.eval(), test_labels)\n",
    "print('Test error: %.1f%%' % test_error)\n",
    "\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.grid(False)\n",
    "plt.xticks(numpy.arange(NUM_LABELS))\n",
    "plt.yticks(numpy.arange(NUM_LABELS))\n",
    "plt.imshow(confusions, cmap=plt.cm.jet, interpolation='nearest');\n",
    "\n",
    "for i, cas in enumerate(confusions):\n",
    "    for j, count in enumerate(cas):\n",
    "        if count > 0:\n",
    "            xoff = .07 * len(str(count))\n",
    "            plt.text(j-xoff, i+.2, int(count), fontsize=9, color='white')\n",
    "\n",
    "\n",
    "# We can see here that we're mostly accurate, with some errors you might expect, e.g., '9' is often confused as '4'.\n",
    "# \n",
    "# Let's do another sanity check to make sure this matches roughly the distribution of our test set, e.g., it seems like we have fewer '5' values.\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "plt.xticks(numpy.arange(NUM_LABELS))\n",
    "plt.hist(numpy.argmax(test_labels, 1));\n",
    "\n",
    "\n",
    "# Indeed, we appear to have fewer 5 labels in the test set. So, on the whole, it seems like our model is learning and our early results are sensible.\n",
    "# \n",
    "# But, we've only done one round of training. We can greatly improve accuracy by training for longer. To try this out, just re-execute the training cell above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: DeprecationWarning: decodestring() is a deprecated alias since Python 3.1, use decodebytes()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded train-images-idx3-ubyte.gz\n",
      "Already downloaded train-labels-idx1-ubyte.gz\n",
      "Already downloaded t10k-images-idx3-ubyte.gz\n",
      "Already downloaded t10k-labels-idx1-ubyte.gz\n",
      "magic number 2051\n",
      "image count 10000\n",
      "rows 28\n",
      "columns 28\n",
      "First 10 pixels: [0 0 0 0 0 0 0 0 0 0]\n",
      "magic number 2049\n",
      "label count 10000\n",
      "First label: 7\n",
      "Extracting /tmp/mnist-data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/mnist-data/t10k-images-idx3-ubyte.gz\n",
      "Training data shape (60000, 28, 28, 1)\n",
      "Extracting /tmp/mnist-data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/mnist-data/t10k-labels-idx1-ubyte.gz\n",
      "Training labels shape (60000, 10)\n",
      "First label vector [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Second label vector [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Validation shape (5000, 28, 28, 1)\n",
      "Train size 55000\n",
      "\n",
      "train_data object: <class 'numpy.ndarray'> (55000, 28, 28, 1)\n",
      "\n",
      "train_labels object: <class 'numpy.ndarray'> (55000, 10)\n",
      "\n",
      "validation_data object: <class 'numpy.ndarray'> (5000, 28, 28, 1)\n",
      "\n",
      "validation_labels object: <class 'numpy.ndarray'> (5000, 10)\n",
      "\n",
      "test_data object: <class 'numpy.ndarray'> (10000, 28, 28, 1)\n",
      "\n",
      "test_labels object: <class 'numpy.ndarray'> (10000, 10)\n",
      "\n",
      " Run complete. data objects sent to binary file  mnist_data.pickle\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# MNIST from scratch (data and partitioning from Google tensorflow container)\n",
    "# source:  https://hub.docker.com/r/tensorflow/tensorflow/\n",
    "# \n",
    "# We begin with a notebook that walks through an example of training a TensorFlow model \n",
    "# to do digit classification using the [MNIST data set](http://yann.lecun.com/exdb/mnist/). \n",
    "# MNIST is a labeled set of images of handwritten digits.\n",
    "# \n",
    "# But rather than building a TensorFlow model, we will export the data to binary\n",
    "# files that we can use to input to machine learning environments such as Scikit Learn.\n",
    "# We use pickle to export the binary objects we need for subsequent modeling.\n",
    "# \n",
    "# An example follows.\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "# ensure common functions across Python 2 and 3\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from IPython.display import Image\n",
    "import base64\n",
    "Image(data=base64.decodestring(\"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\".encode('utf-8')), embed=True)\n",
    "\n",
    "\n",
    "# We're going to be building a model that recognizes these digits as 5, 0, and 4.\n",
    "# \n",
    "# # Imports and input data\n",
    "# \n",
    "# We'll proceed in steps, beginning with importing and inspecting the MNIST data. This doesn't have anything to do with TensorFlow in particular -- we're just downloading the data archive.\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import os\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "\n",
    "SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\n",
    "WORK_DIRECTORY = \"/tmp/mnist-data\"\n",
    "\n",
    "def maybe_download(filename):\n",
    "    \"\"\"A helper to download the data files if not present.\"\"\"\n",
    "    if not os.path.exists(WORK_DIRECTORY):\n",
    "        os.mkdir(WORK_DIRECTORY)\n",
    "    filepath = os.path.join(WORK_DIRECTORY, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        filepath, _ = urlretrieve(SOURCE_URL + filename, filepath)\n",
    "        statinfo = os.stat(filepath)\n",
    "        print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "    else:\n",
    "        print('Already downloaded', filename)\n",
    "    return filepath\n",
    "\n",
    "train_data_filename = maybe_download('train-images-idx3-ubyte.gz')\n",
    "train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')\n",
    "test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')\n",
    "test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "\n",
    "# ## Working with the images\n",
    "# \n",
    "# Now we have the files, but the format requires a bit of pre-processing before we can work with it. The data is gzipped, requiring us to decompress it. And, each of the images are grayscale-encoded with values from [0, 255]; we'll normalize these to [-0.5, 0.5].\n",
    "# \n",
    "# Let's try to unpack the data using the documented format:\n",
    "# \n",
    "#     [offset] [type]          [value]          [description] \n",
    "#     0000     32 bit integer  0x00000803(2051) magic number \n",
    "#     0004     32 bit integer  60000            number of images \n",
    "#     0008     32 bit integer  28               number of rows \n",
    "#     0012     32 bit integer  28               number of columns \n",
    "#     0016     unsigned byte   ??               pixel \n",
    "#     0017     unsigned byte   ??               pixel \n",
    "#     ........ \n",
    "#     xxxx     unsigned byte   ??               pixel\n",
    "#     \n",
    "# Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).\n",
    "# \n",
    "# We'll start by reading the first image from the test data as a sanity check.\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "import gzip, binascii, struct, numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with gzip.open(test_data_filename) as f:\n",
    "    # Print the header fields.\n",
    "    for field in ['magic number', 'image count', 'rows', 'columns']:\n",
    "        # struct.unpack reads the binary data provided by f.read.\n",
    "        # The format string '>i' decodes a big-endian integer, which\n",
    "        # is the encoding of the data.\n",
    "        print(field, struct.unpack('>i', f.read(4))[0])\n",
    "    \n",
    "    # Read the first 28x28 set of pixel values. \n",
    "    # Each pixel is one byte, [0, 255], a uint8.\n",
    "    buf = f.read(28 * 28)\n",
    "    image = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
    "  \n",
    "    # Print the first few values of image.\n",
    "    print('First 10 pixels:', image[:10])\n",
    "\n",
    "\n",
    "# The first 10 pixels are all 0 values. Not very interesting, but also unsurprising. We'd expect most of the pixel values to be the background color, 0.\n",
    "# \n",
    "# We could print all 28 * 28 values, but what we really need to do to make sure we're reading our data properly is look at an image.\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "\n",
    "# We'll show the image and its pixel value histogram side-by-side.\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "# To interpret the values as a 28x28 image, we need to reshape\n",
    "# the numpy array, which is one dimensional.\n",
    "ax1.imshow(image.reshape(28, 28), cmap=plt.cm.Greys);\n",
    "\n",
    "ax2.hist(image, bins=20, range=[0,255]);\n",
    "\n",
    "\n",
    "# The large number of 0 values correspond to the background of the image, another large mass of value 255 is black, and a mix of grayscale transition values in between.\n",
    "# \n",
    "# Both the image and histogram look sensible. But, it's good practice when training image models to normalize values to be centered around 0.\n",
    "# \n",
    "# We'll do that next. The normalization code is fairly short, and it may be tempting to assume we haven't made mistakes, but we'll double-check by looking at the rendered input and histogram again. Malformed inputs are a surprisingly common source of errors when developing new models.\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "# Let's convert the uint8 image to 32 bit floats and rescale \n",
    "# the values to be centered around 0, between [-0.5, 0.5]. \n",
    "# \n",
    "# We again plot the image and histogram to check that we \n",
    "# haven't mangled the data.\n",
    "scaled = image.astype(numpy.float32)\n",
    "scaled = (scaled - (255 / 2.0)) / 255\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(scaled.reshape(28, 28), cmap=plt.cm.Greys);\n",
    "ax2.hist(scaled, bins=20, range=[-0.5, 0.5]);\n",
    "\n",
    "\n",
    "# Great -- we've retained the correct image data while properly rescaling to the range [-0.5, 0.5].\n",
    "# \n",
    "# ## Reading the labels\n",
    "# \n",
    "# Let's next unpack the test label data. The format here is similar: a magic number followed by a count followed by the labels as `uint8` values. In more detail:\n",
    "# \n",
    "#     [offset] [type]          [value]          [description] \n",
    "#     0000     32 bit integer  0x00000801(2049) magic number (MSB first) \n",
    "#     0004     32 bit integer  10000            number of items \n",
    "#     0008     unsigned byte   ??               label \n",
    "#     0009     unsigned byte   ??               label \n",
    "#     ........ \n",
    "#     xxxx     unsigned byte   ??               label\n",
    "# \n",
    "# As with the image data, let's read  the first test set value to sanity check our input path. We'll expect a 7.\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "with gzip.open(test_labels_filename) as f:\n",
    "    # Print the header fields.\n",
    "    for field in ['magic number', 'label count']:\n",
    "        print(field, struct.unpack('>i', f.read(4))[0])\n",
    "\n",
    "    print('First label:', struct.unpack('B', f.read(1))[0])\n",
    "\n",
    "\n",
    "# Indeed, the first label of the test set is 7.\n",
    "# \n",
    "# ## Forming the training, testing, and validation data sets\n",
    "# \n",
    "# Now that we understand how to read a single element, we can read a much larger set that we'll use for training, testing, and validation.\n",
    "# \n",
    "# ### Image data\n",
    "# \n",
    "# The code below is a generalization of our prototyping above that reads the entire test and training data set.\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "IMAGE_SIZE = 28\n",
    "PIXEL_DEPTH = 255\n",
    "\n",
    "def extract_data(filename, num_images):\n",
    "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "  \n",
    "    For MNIST data, the number of channels is always 1.\n",
    "\n",
    "    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
    "    \"\"\"\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        # Skip the magic number and dimensions; we know these values.\n",
    "        bytestream.read(16)\n",
    "\n",
    "        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images)\n",
    "        data = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.float32)\n",
    "        data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "        data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "        return data\n",
    "\n",
    "train_data = extract_data(train_data_filename, 60000)\n",
    "test_data = extract_data(test_data_filename, 10000)\n",
    "\n",
    "\n",
    "# A crucial difference here is how we `reshape` the array of pixel values. Instead of one image that's 28x28, we now have a set of 60,000 images, each one being 28x28. We also include a number of channels, which for grayscale images as we have here is 1.\n",
    "# \n",
    "# Let's make sure we've got the reshaping parameters right by inspecting the dimensions and the first two images. (Again, mangled input is a very common source of errors.)\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "print('Training data shape', train_data.shape)\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(train_data[0].reshape(28, 28), cmap=plt.cm.Greys);\n",
    "ax2.imshow(train_data[1].reshape(28, 28), cmap=plt.cm.Greys);\n",
    "\n",
    "\n",
    "# Looks good. Now we know how to index our full set of training and test images.\n",
    "\n",
    "# ### Label data\n",
    "# \n",
    "# Let's move on to loading the full set of labels. As is typical in classification problems, we'll convert our input labels into a [1-hot](https://en.wikipedia.org/wiki/One-hot) encoding over a length 10 vector corresponding to 10 digits. The vector [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], for example, would correspond to the digit 1.\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "NUM_LABELS = 10\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"Extract the labels into a 1-hot matrix [image index, label index].\"\"\"\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        # Skip the magic number and count; we know these values.\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
    "    # Convert to dense 1-hot representation.\n",
    "    return (numpy.arange(NUM_LABELS) == labels[:, None]).astype(numpy.float32)\n",
    "\n",
    "train_labels = extract_labels(train_labels_filename, 60000)\n",
    "test_labels = extract_labels(test_labels_filename, 10000)\n",
    "\n",
    "\n",
    "# As with our image data, we'll double-check that our 1-hot encoding of the first few values matches our expectations.\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "print('Training labels shape', train_labels.shape)\n",
    "print('First label vector', train_labels[0])\n",
    "print('Second label vector', train_labels[1])\n",
    "\n",
    "\n",
    "# The 1-hot encoding looks reasonable.\n",
    "# \n",
    "# ### Segmenting data into training, test, and validation\n",
    "# \n",
    "# The final step in preparing our data is to split it into three sets: training, test, and validation. This isn't the format of the original data set, so we'll take a small slice of the training data and treat that as our validation set.\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "VALIDATION_SIZE = 5000\n",
    "\n",
    "validation_data = train_data[:VALIDATION_SIZE, :, :, :]\n",
    "validation_labels = train_labels[:VALIDATION_SIZE]\n",
    "train_data = train_data[VALIDATION_SIZE:, :, :, :]\n",
    "train_labels = train_labels[VALIDATION_SIZE:]\n",
    "\n",
    "train_size = train_labels.shape[0]\n",
    "\n",
    "print('Validation shape', validation_data.shape)\n",
    "print('Train size', train_size)\n",
    "\n",
    "# End of code from Google mnist_from_scratch program\n",
    "\n",
    "# We use pickle to export the binary objects we need for subsequent modeling.\n",
    "# See documentation at https://docs.python.org/3/library/pickle.html\n",
    "\n",
    "# check data for pickle dump\n",
    "print('\\ntrain_data object:', type(train_data), train_data.shape)    \n",
    "print('\\ntrain_labels object:', type(train_labels),  train_labels.shape)  \n",
    "print('\\nvalidation_data object:', type(validation_data),  validation_data.shape)  \n",
    "print('\\nvalidation_labels object:', type(validation_labels),  validation_labels.shape)  \n",
    "print('\\ntest_data object:', type(test_data),  test_data.shape)  \n",
    "print('\\ntest_labels object:', type(test_labels),  test_labels.shape)  \n",
    "\n",
    "\n",
    "import pickle  # used for dumping and loading binary files\n",
    "\n",
    "# define collection of objects to export as binary file using pickle.\n",
    "data = {\n",
    "    'train_data': train_data,\n",
    "    'train_labels': train_labels,\n",
    "    'validation_data': validation_data,\n",
    "    'validation_labels': validation_labels,\n",
    "    'test_data': test_data,\n",
    "    'test_labels': test_labels}\n",
    "\n",
    "# write to binary file\n",
    "with open('mnist_data.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print('\\n Run complete. data objects sent to binary file  mnist_data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_data object: <class 'numpy.ndarray'> (55000, 28, 28, 1)\n",
      "\n",
      "train_labels object: <class 'numpy.ndarray'> (55000, 10)\n",
      "\n",
      "validation_data object: <class 'numpy.ndarray'> (5000, 28, 28, 1)\n",
      "\n",
      "validation_labels object: <class 'numpy.ndarray'> (5000, 10)\n",
      "\n",
      "test_data object: <class 'numpy.ndarray'> (10000, 28, 28, 1)\n",
      "\n",
      "test_labels object: <class 'numpy.ndarray'> (10000, 10)\n",
      "\n",
      "data input complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# An earlier program   3_mnist_from_scratch-data-prep-v001.py\n",
    "# gathered MNIST from scratch (data and partitioning from Google tensorflow container)\n",
    "# Much of the source came from:  https://hub.docker.com/r/tensorflow/tensorflow/\n",
    "# \n",
    "# We use pickle to export the binary objects we use here for subsequent modeling.\n",
    "# \n",
    "\n",
    "# In[1]:\n",
    "\n",
    "# ensure common functions across Python 2 and 3\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# We use pickle to import the binary objects we need for subsequent modeling.\n",
    "# See documentation at https://docs.python.org/3/library/pickle.html\n",
    "\n",
    "import pickle  # used for dumping and loading binary files\n",
    "\n",
    "# earlier data collection was defined as follows for pickle.\n",
    "# data = {\n",
    "#     'train_data': train_data,\n",
    "#     'train_labels': train_labels,\n",
    "#     'validation_data': validation_data,\n",
    "#     'validation_labels': validation_labels,\n",
    "#     'test_data': test_data,\n",
    "#     'test_labels': test_labels}\n",
    "\n",
    "with open('mnist_data.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# extract objects from the dictionary object data\n",
    "train_data = data['train_data']\n",
    "train_labels = data['train_labels'] \n",
    "validation_data = data['validation_data'] \n",
    "validation_labels = data['validation_labels'] \n",
    "test_data = data['test_data'] \n",
    "test_labels = data['test_labels']  \n",
    "    \n",
    "# check data from pickle load\n",
    "print('\\ntrain_data object:', type(train_data), train_data.shape)    \n",
    "print('\\ntrain_labels object:', type(train_labels),  train_labels.shape)  \n",
    "print('\\nvalidation_data object:', type(validation_data),  validation_data.shape)  \n",
    "print('\\nvalidation_labels object:', type(validation_labels),  validation_labels.shape)  \n",
    "print('\\ntest_data object:', type(test_data),  test_data.shape)  \n",
    "print('\\ntest_labels object:', type(test_labels),  test_labels.shape)  \n",
    "\n",
    "print('\\ndata input complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_data object: <class 'numpy.ndarray'> (55000, 28, 28, 1)\n",
      "\n",
      "train_labels object: <class 'numpy.ndarray'> (55000, 10)\n",
      "\n",
      "validation_data object: <class 'numpy.ndarray'> (5000, 28, 28, 1)\n",
      "\n",
      "validation_labels object: <class 'numpy.ndarray'> (5000, 10)\n",
      "\n",
      "test_data object: <class 'numpy.ndarray'> (10000, 28, 28, 1)\n",
      "\n",
      "test_labels object: <class 'numpy.ndarray'> (10000, 10)\n",
      "\n",
      "data input complete\n",
      "\n",
      "X_train object: <class 'numpy.ndarray'> (55000, 784)\n",
      "\n",
      "y_train object: <class 'numpy.ndarray'> (55000,)\n",
      "\n",
      "X_validation object: <class 'numpy.ndarray'> (5000, 784)\n",
      "\n",
      "y_validation object: <class 'numpy.ndarray'> (5000,)\n",
      "\n",
      "X_test object: <class 'numpy.ndarray'> (10000, 784)\n",
      "\n",
      "y_test object: <class 'numpy.ndarray'> (10000,)\n",
      "\n",
      "X_train_expanded object: <class 'numpy.ndarray'> (60000, 784)\n",
      "\n",
      "y_train_expanded object: <class 'numpy.ndarray'> (60000, 1)\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: ANN-2-Layers-10-Nodes-per-Layer\n",
      "\n",
      "  Specification of method: MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(10, 10), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=9999, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.083333, verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing time (seconds): 360.742038\n",
      "\n",
      "Training set accuracy: 0.940650\n",
      "\n",
      "Test set accuracy: 0.928800\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: ANN-2-Layers-20-Nodes-per-Layer\n",
      "\n",
      "  Specification of method: MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(20, 20), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=9999, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.083333, verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing time (seconds): 827.112931\n",
      "\n",
      "Training set accuracy: 0.974183\n",
      "\n",
      "Test set accuracy: 0.951100\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: ANN-5-Layers-10-Nodes-per-Layer\n",
      "\n",
      "  Specification of method: MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(10, 10, 10, 10, 10), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=9999, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.083333, verbose=False, warm_start=False)\n",
      "\n",
      "Processing time (seconds): 320.243819\n",
      "\n",
      "Training set accuracy: 0.946883\n",
      "\n",
      "Test set accuracy: 0.932300\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "Method: ANN-5-Layers-20-Nodes-per-Layer\n",
      "\n",
      "  Specification of method: MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(20, 20, 20, 20, 20), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=9999, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.083333, verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing time (seconds): 1085.516389\n",
      "\n",
      "Training set accuracy: 0.979083\n",
      "\n",
      "Test set accuracy: 0.948300\n",
      "\n",
      "Benchmark Experiment: Scikit Learn Artificial Neural Networks\n",
      "\n",
      "                       Method Name  Layers  Nodes per Layer  Processing Time  \\\n",
      "0  ANN-2-Layers-10-Nodes-per-Layer       2               10       360.742038   \n",
      "1  ANN-2-Layers-20-Nodes-per-Layer       2               20       827.112931   \n",
      "2  ANN-5-Layers-10-Nodes-per-Layer       5               10       320.243819   \n",
      "3  ANN-5-Layers-20-Nodes-per-Layer       5               20      1085.516389   \n",
      "\n",
      "   Training Set Accuracy  Test Set Accuracy  \n",
      "0               0.940650             0.9288  \n",
      "1               0.974183             0.9511  \n",
      "2               0.946883             0.9323  \n",
      "3               0.979083             0.9483  \n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# Demonstration of Benchmark Experiment using Scikit Learn for Artificial Neural Networks\n",
    "# Utilizes the MNIST data\n",
    "\n",
    "# Example developed by Thomas W. Miller 2017-10-31\n",
    "\n",
    "# An earlier program   3_mnist_from_scratch-data-prep-v001.py\n",
    "# gathered MNIST from scratch (data and partitioning from Google tensorflow container)\n",
    "# Source for the initial data:  https://hub.docker.com/r/tensorflow/tensorflow/\n",
    "# We used pickle package to export data to binary files.\n",
    "# \n",
    "# Documentation for Scikit Learn neural networks (multi-layer perceptron classifier):\n",
    "#   http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "\n",
    "# Possible visualization of fitted models is described in\n",
    "# http://scikit-learn.org/stable/auto_examples/neural_networks/\n",
    "#     plot_mnist_filters.html#sphx-glr-auto-examples-neural-networks-plot-mnist-filters-py\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "# ensure common functions across Python 2 and 3\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# We use pickle to import the binary objects we need for subsequent modeling.\n",
    "# See documentation at https://docs.python.org/3/library/pickle.html\n",
    "\n",
    "import pickle  # used for dumping and loading binary files\n",
    "\n",
    "# earlier data collection was defined as follows for pickle.\n",
    "# data = {\n",
    "#     'train_data': train_data,\n",
    "#     'train_labels': train_labels,\n",
    "#     'validation_data': validation_data,\n",
    "#     'validation_labels': validation_labels,\n",
    "#     'test_data': test_data,\n",
    "#     'test_labels': test_labels}\n",
    "\n",
    "with open('mnist_data.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# extract objects from the dictionary object data\n",
    "train_data = data['train_data']\n",
    "train_labels = data['train_labels'] \n",
    "validation_data = data['validation_data'] \n",
    "validation_labels = data['validation_labels'] \n",
    "test_data = data['test_data'] \n",
    "test_labels = data['test_labels']  \n",
    "    \n",
    "# check data from pickle load\n",
    "print('\\ntrain_data object:', type(train_data), train_data.shape)    \n",
    "print('\\ntrain_labels object:', type(train_labels),  train_labels.shape)  \n",
    "print('\\nvalidation_data object:', type(validation_data),  validation_data.shape)  \n",
    "print('\\nvalidation_labels object:', type(validation_labels),  validation_labels.shape)  \n",
    "print('\\ntest_data object:', type(test_data),  test_data.shape)  \n",
    "print('\\ntest_labels object:', type(test_labels),  test_labels.shape)  \n",
    "\n",
    "print('\\ndata input complete')\n",
    "\n",
    "# In[2]\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# user-defined function to convert binary digits to digits 0-9\n",
    "def label_transform(y_in):\n",
    "    for i in range(len(y_in)):\n",
    "        if (y_in[i] == 1): return i\n",
    "\n",
    "y_train = []    \n",
    "for j in range(train_labels.shape[0]):\n",
    "    y_train.append(label_transform(train_labels[j,]))  \n",
    "y_train = np.asarray(y_train)    \n",
    "\n",
    "y_validation = []    \n",
    "for j in range(validation_labels.shape[0]):\n",
    "    y_validation.append(label_transform(validation_labels[j,]))  \n",
    "y_validation = np.asarray(y_validation)    \n",
    "\n",
    "y_test = []    \n",
    "for j in range(test_labels.shape[0]):\n",
    "    y_test.append(label_transform(test_labels[j,]))  \n",
    "y_test = np.asarray(y_test)    \n",
    "    \n",
    "# 28x28 matrix of entries converted to vector of 784 entries    \n",
    "X_train = train_data.reshape(55000, 784)\n",
    "X_validation = validation_data.reshape(5000, 784)    \n",
    "X_test = test_data.reshape(10000, 784)    \n",
    "\n",
    "# check data intended for Scikit Learn input\n",
    "print('\\nX_train object:', type(X_train), X_train.shape)    \n",
    "print('\\ny_train object:', type(y_train),  y_train.shape)  \n",
    "print('\\nX_validation object:', type(X_validation),  X_validation.shape)  \n",
    "print('\\ny_validation object:', type(y_validation),  y_validation.shape)  \n",
    "print('\\nX_test object:', type(X_test),  X_test.shape)  \n",
    "print('\\ny_test object:', type(y_test),  y_test.shape)      \n",
    "# In[3] \n",
    "\n",
    "# Scikit Learn MLP Classification does validation internally, \n",
    "# so there is with no need for a separate validation set.\n",
    "# We will combine the train and validation sets.\n",
    "\n",
    "X_train_expanded = np.vstack((X_train, X_validation))\n",
    "y_train_expanded = np.vstack((y_train.reshape(55000,1), y_validation.reshape(5000,1)))\n",
    "\n",
    "print('\\nX_train_expanded object:', type(X_train_expanded),  X_train_expanded.shape)  \n",
    "print('\\ny_train_expanded object:', type(y_train_expanded), y_train_expanded.shape)  \n",
    "# In[4]\n",
    "\n",
    "RANDOM_SEED = 9999\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "names = ['ANN-2-Layers-10-Nodes-per-Layer',\n",
    "         'ANN-2-Layers-20-Nodes-per-Layer',\n",
    "         'ANN-5-Layers-10-Nodes-per-Layer',\n",
    "         'ANN-5-Layers-20-Nodes-per-Layer']\n",
    "\n",
    "layers = [2, 2, 5, 5]\n",
    "nodes_per_layer = [10, 20, 10, 20]\n",
    "treatment_condition = [(10, 10), \n",
    "                       (20, 20), \n",
    "                       (10, 10, 10, 10, 10), \n",
    "                       (20, 20, 20, 20, 20)] \n",
    "\n",
    "# note that validation is included in the method  \n",
    "# for validation_fraction 0.083333, note that 60000 * 0.83333 = 5000    \n",
    "methods = [MLPClassifier(hidden_layer_sizes=treatment_condition[0], activation='relu', \n",
    "              solver='adam', alpha=0.0001, batch_size='auto', \n",
    "              learning_rate='constant', learning_rate_init=0.001, \n",
    "              power_t=0.5, max_iter=200, shuffle=True, \n",
    "              random_state=RANDOM_SEED, \n",
    "              tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "              nesterovs_momentum=True, early_stopping=False, \n",
    "              validation_fraction=0.083333, beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n",
    "    MLPClassifier(hidden_layer_sizes=treatment_condition[1], activation='relu', \n",
    "              solver='adam', alpha=0.0001, batch_size='auto', \n",
    "              learning_rate='constant', learning_rate_init=0.001, \n",
    "              power_t=0.5, max_iter=200, shuffle=True, \n",
    "              random_state=RANDOM_SEED, \n",
    "              tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "              nesterovs_momentum=True, early_stopping=False, \n",
    "              validation_fraction=0.083333, beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n",
    "    MLPClassifier(hidden_layer_sizes=treatment_condition[2], activation='relu', \n",
    "              solver='adam', alpha=0.0001, batch_size='auto', \n",
    "              learning_rate='constant', learning_rate_init=0.001, \n",
    "              power_t=0.5, max_iter=200, shuffle=True, \n",
    "              random_state=RANDOM_SEED, \n",
    "              tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "              nesterovs_momentum=True, early_stopping=False, \n",
    "              validation_fraction=0.083333, beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n",
    "    MLPClassifier(hidden_layer_sizes=treatment_condition[3], activation='relu', \n",
    "              solver='adam', alpha=0.0001, batch_size='auto', \n",
    "              learning_rate='constant', learning_rate_init=0.001, \n",
    "              power_t=0.5, max_iter=200, shuffle=True, \n",
    "              random_state=RANDOM_SEED, \n",
    "              tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "              nesterovs_momentum=True, early_stopping=False, \n",
    "              validation_fraction=0.083333, beta_1=0.9, beta_2=0.999, epsilon=1e-08)]\n",
    " \n",
    "index_for_method = 0 \n",
    "training_performance_results = []\n",
    "test_performance_results = []\n",
    "processing_time = []\n",
    "   \n",
    "for name, method in zip(names, methods):\n",
    "    print('\\n------------------------------------')\n",
    "    print('\\nMethod:', name)\n",
    "    print('\\n  Specification of method:', method)\n",
    "    start_time = time.clock()\n",
    "    method.fit(X_train, y_train)\n",
    "    end_time = time.clock()\n",
    "    runtime = end_time - start_time  # seconds of wall-clock time \n",
    "    print(\"\\nProcessing time (seconds): %f\" % runtime)        \n",
    "    processing_time.append(runtime)\n",
    "\n",
    "    # mean accuracy of prediction in training set\n",
    "    training_performance = method.score(X_train_expanded, y_train_expanded)\n",
    "    print(\"\\nTraining set accuracy: %f\" % training_performance)\n",
    "    training_performance_results.append(training_performance)\n",
    "\n",
    "    # mean accuracy of prediction in test set\n",
    "    test_performance = method.score(X_test, y_test)\n",
    "    print(\"\\nTest set accuracy: %f\" % test_performance)\n",
    "    test_performance_results.append(test_performance)\n",
    "                \n",
    "    index_for_method += 1\n",
    "\n",
    "# aggregate the results for final report\n",
    "# using OrderedDict to preserve the order of variables in DataFrame    \n",
    "from collections import OrderedDict  \n",
    "\n",
    "results = pd.DataFrame(OrderedDict([('Method Name', names),\n",
    "                        ('Layers', layers),\n",
    "                        ('Nodes per Layer', nodes_per_layer),\n",
    "                        ('Processing Time', processing_time),\n",
    "                        ('Training Set Accuracy', training_performance_results),\n",
    "                        ('Test Set Accuracy', test_performance_results)]))\n",
    "\n",
    "print('\\nBenchmark Experiment: Scikit Learn Artificial Neural Networks\\n')\n",
    "print(results)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
